* OmicIDX Builder

This project includes a command-line utility and supporting code to
process and build the OmicIDX applications and data resources.

Related OmicIDX projects can be found on the [[https://github.com/omicidx/][OmicIDX Github Organization]].

** Roadmap

- [-] Bigquery tables
  - [X] SRA 
  - [X] Biosample
  - [ ] GEO
- [-] JSON dump files
  - [X] SRA
  - [X] Biosample
  - [ ] GEO
- [-] REST API
  - [X] SRA
  - [X] Biosample
  - [ ] GEO
- [-] GraphQL API
  - [ ] SRA
  - [ ] Biosample
  - [ ] GEO

* Installation for local usage

** Installation

#+BEGIN_SRC bash
  pip install poetry
  poetry install omicidx_builder
#+END_SRC


** Google setup

TODO

* Pipeline

The data processing pipelines are run from the command-line. Notes are below. 

** SRA

#+begin_src bash
omicidx_builder sra --help
#+end_src

#+begin_src bash
omicidx_builder sra download NCBI_SRA_Mirroring_20190801_Full
cd NCBI_SRA_Mirroring_20190801_Full
omicidx_builder sra parse-entity study
omicidx_builder sra parse-entity sample
omicidx_builder sra parse-entity experiment
omicidx_builder sra parse-entity run
cd ..
omicidx_builder sra upload NCBI_SRA_Mirroring_20190801_Full
omicidx_builder sra load-sra-data-to-bigquery
omicidx_builder sra sra-to-bigquery
omicidx_builder sra sra-bigquery-for-elasticsearch
omicidx_builder sra gcs-dump
omicidx_builder sra gcs-to-elasticsearch
#+end_src

** Biosample

#+BEGIN_SRC bash
omicidx_builder biosample --help
#+END_SRC

Here are the steps. This requires about 20GB of local storage.

#+BEGIN_SRC bash
  omicidx_builder biosample download
  omicidx_builder biosample parse biosample_set.xml.gz biosample.json
  omicidx_builder biosample upload
  omicidx_builder biosample load
  omicidx_builder biosample etl-to-public
  omicidx_builder biosample gcs-dump
  omicidx_builder biosample gcs-to-elasticsearch
#+END_SRC

* elasticsearch

#+BEGIN_SRC python
import elasticsearch_dsl
import omicidx_builder.elasticsearch_utils as es
searcher = elasticsearch_dsl.Search(using = es.get_client())
from elasticsearch_dsl import Search

s = (searcher.index("sra_study")
    .query("match", title="cancer")   
    .exclude("match", description="cancer"))

response = s.execute()

for hit in response:
    print(hit.meta.score, hit.title)

for tag in response.aggregations.per_tag.buckets:
    print(tag.key, tag.max_lines.value)
#+END_SRC
* Development
** running tests

#+BEGIN_SRC bash
poetry run pytest --cov=omicidx_builder tests
#+END_SRC

Running long-running tests:

#+BEGIN_SRC bash
LONG_TESTS=1 poetry run pytest --cov=omicidx_builder tests
#+END_SRC
